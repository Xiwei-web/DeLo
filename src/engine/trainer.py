import time
import numpy as np
import torch
import torch.nn.functional as F
from loguru import logger
from torch.cuda.amp import GradScaler, autocast
from tqdm import tqdm

from optim import build_criterion, build_lr_scheduler, build_optimizer
from utils import AverageMeter, Checkpoint, ProgressMeter, Throughout
from .evaluator import Evaluator


class Trainer:
    def __init__(self, cfg, dataloaders, model, tensorboard_logger):
        super().__init__()
        self.cfg = cfg
        self.task_id = 0
        self.current_epoch = 0
        self.current_iter = 0
        self.epochs = cfg.train.EPOCHS
        self.num_tasks = cfg.model.NUM_TASKS
        self.num_labels_per_task = cfg.model.NUM_LABELS_PER_TASK
        self.dataloaders = dataloaders
        self.tensorboard_logger = tensorboard_logger

        self.device = torch.device("cpu") if cfg.train.GPU is None else (
            torch.device(f"cuda:{cfg.train.GPU[0]}") if isinstance(cfg.train.GPU, list) else torch.device(f"cuda:{cfg.train.GPU}")
        )

        self.model = model.to(self.device)
        self.criterion = build_criterion(cfg.train.criterion)
        self.evaluator = Evaluator(cfg.test)
        self.scaler = GradScaler()
        self.checkpoint = Checkpoint(cfg.OUTPUT_DIR)

        # å°†optimizerå’Œlr_scheduleråˆå§‹åŒ–ä¸ºNoneï¼Œå®ƒä»¬å°†åœ¨prepare_incremental_taskä¸­è¢«åˆ›å»º
        self.optimizer = None
        self.lr_scheduler = None
        self.lr_scheduler_interval = None

        if cfg.train.CHECKPOINT:
            self.load_checkpoint(cfg.train.CHECKPOINT, cfg.train.CHECKPOINT_TASK_ID)

        if cfg.train.THROUGHOUT:
            self.throughout = Throughout()

    def train(self):
        if self.cfg.train.ONLY_VAL:
            logger.info("Debug model! Only run a validation function!")
            self.prepare_incremental_task(0)
            metrics = self.validate()
            self.display_metrics(metrics)
            return

        current_task_id = self.task_id
        result_matrix = np.zeros((self.num_tasks, self.num_tasks))

        # ======================= æ¢é’ˆå˜é‡åˆå§‹åŒ– =======================
        # æˆ‘ä»¬å°†å­˜å‚¨Task 0æŸä¸ªå…³é”®å‚æ•°çš„æ€»å’Œï¼Œä½œä¸ºå®ƒçš„"æŒ‡çº¹"
        task0_param_fingerprint = None
        # ==========================================================

        for task_id in range(current_task_id, self.num_tasks):
            best_score = 0.0
            self.prepare_incremental_task(task_id)

            # ======================= æ¢é’ˆ #2ï¼šæ–°ä»»åŠ¡å¼€å§‹å‰ =======================
            if task_id > 0 and task0_param_fingerprint is not None:
                try:
                    # å†æ¬¡è·å–Task 0çš„åŒä¸€ä¸ªå‚æ•°
                    param_to_check_before = self.model.backbone.vilt.encoder.layer[0].attention.attention.query.vision_adapter.lora_A_pools[0]
                    sum_before = param_to_check_before.sum().item()
                    logger.info(f"[æ¢é’ˆ #2] Task {task_id} å¼€å§‹å‰, Task 0å‚æ•°æŒ‡çº¹: {sum_before:.6f}")
                    if abs(sum_before - task0_param_fingerprint) > 1e-6:
                        logger.critical(f"!!! [æ¢é’ˆ #2] è‡´å‘½é”™è¯¯ï¼šTask 0çš„å‚æ•°åœ¨ä»»åŠ¡è¿‡æ¸¡æœŸé—´è¢«æ”¹å˜äº†ï¼æœŸæœ›å€¼: {task0_param_fingerprint:.6f}, å®é™…å€¼: {sum_before:.6f}")
                except Exception as e:
                    logger.error(f"[æ¢é’ˆ #2] æ— æ³•è·å–å‚æ•°: {e}")
            # ====================================================================

            for epoch in range(self.epochs):
                self.current_epoch = epoch
                self.train_loop()
                
                # ä¸ºäº†å¿«é€Ÿè°ƒè¯•ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ¯ä¸ªepochåéƒ½éªŒè¯
                metrics = self.validate()
                score = list(metrics[-1].values())[0].item()
                self.display_metrics(metrics)
                
                if best_score < score:
                    best_score = score
                    logger.info("New best score: {:.2f}.".format(best_score))
                    self.save_checkpoint(metrics, task_id=task_id, is_best=True)

            # æ¯ä¸ªä»»åŠ¡è®­ç»ƒç»“æŸåï¼Œè¿›è¡Œæœ€ç»ˆçš„éªŒè¯å’Œä¿å­˜
            metrics = self.validate()
            self.display_metrics(metrics)
            self.save_checkpoint(metrics, task_id=task_id, is_best=False)

            for tid, metric in enumerate(metrics):
                result_matrix[task_id][tid] = metric[self.cfg.test.NAME]

            # ======================= æ¢é’ˆ #1 & #3ï¼šä»»åŠ¡è®­ç»ƒç»“æŸå =======================
            if task_id == 0:
                # æ¢é’ˆ #1: åœ¨Task 0è®­ç»ƒç»“æŸåï¼Œè®°å½•ä¸‹å®ƒçš„å‚æ•°"æŒ‡çº¹"
                try:
                    param_to_check_after_task0 = self.model.backbone.vilt.encoder.layer[0].attention.attention.query.vision_adapter.lora_A_pools[0]
                    task0_param_fingerprint = param_to_check_after_task0.sum().item()
                    logger.info(f"[æ¢é’ˆ #1] Task 0 è®­ç»ƒç»“æŸ, è®°å½•ä¸‹å‚æ•°æŒ‡çº¹: {task0_param_fingerprint:.6f}")
                except Exception as e:
                    logger.error(f"[æ¢é’ˆ #1] æ— æ³•è·å–å‚æ•°: {e}")
            else:
                # æ¢é’ˆ #3: åœ¨Task 1 (æˆ–æ›´é«˜) è®­ç»ƒç»“æŸåï¼Œæ£€æŸ¥Task 0çš„å‚æ•°æ˜¯å¦è¢«"æ±¡æŸ“"
                try:
                    param_to_check_after_task1 = self.model.backbone.vilt.encoder.layer[0].attention.attention.query.vision_adapter.lora_A_pools[0]
                    sum_after = param_to_check_after_task1.sum().item()
                    logger.info(f"[æ¢é’ˆ #3] Task {task_id} è®­ç»ƒç»“æŸ, Task 0å‚æ•°æŒ‡çº¹: {sum_after:.6f}")
                    if abs(sum_after - task0_param_fingerprint) > 1e-6:
                        logger.critical(f"!!! [æ¢é’ˆ #3] è‡´å‘½é”™è¯¯ï¼šTask 0çš„å‚æ•°åœ¨è®­ç»ƒTask {task_id}æ—¶è¢«æ”¹å˜äº†ï¼æœŸæœ›å€¼: {task0_param_fingerprint:.6f}, å®é™…å€¼: {sum_after:.6f}")
                except Exception as e:
                    logger.error(f"[æ¢é’ˆ #3] æ— æ³•è·å–å‚æ•°: {e}")
            # ========================================================================

        ap, fg, last = self.evaluator.compute_cl_metric(result_matrix)
        logger.info(f"AP: {ap:.2f}, Forget: {fg:.2f}, Last: {last:.2f}")
        return ap

    def train_loop(self):
        batch_time = AverageMeter('Time', ':6.3f')
        data_time = AverageMeter('Data', ':6.3f')
        total_losses = AverageMeter('TotalLoss', ':6.3f')
        cls_losses = AverageMeter('ClsLoss', ':6.3f')
        align_losses = AverageMeter('AlignLoss', ':6.3f')
        cons_losses = AverageMeter('ConsistLoss', ':6.3f')

        progress = ProgressMeter(
            len(self.train_dataloader),
            [batch_time, data_time, total_losses, cls_losses, align_losses, cons_losses],
            prefix="Epoch: [{}/{}]".format(self.current_epoch + 1, self.epochs),
        )

        self.model.train()
        task0_param_to_watch = None
        task0_param_before_sum = None

        if self.task_id > 0:
            try:
                task0_param_to_watch = self.model.backbone.vilt.encoder.layer[0].attention.attention.query.vision_adapter.lora_A_pools[0]
                task0_param_before_sum = task0_param_to_watch.sum().item()
            except Exception as e:
                logger.error(f"[æ¢é’ˆ] æ— æ³•è·å–è¦ç›‘æ§çš„Task 0å‚æ•°: {e}")

        end = time.perf_counter()

        for it, batch in enumerate(self.train_dataloader):
            if self.cfg.train.THROUGHOUT:
                self.throughout.tick(len(batch["labels"]))

            self.current_iter += 1
            data_time.update(time.perf_counter() - end)

            self.optimizer.zero_grad()
            inputs = batch['inputs'].to(self.device)
            labels = batch['labels'].to(self.device)
            missing_types = batch['missing_types'].to(self.device)

            batch['inputs'] = inputs
            batch['labels'] = labels
            batch['missing_types'] = missing_types

            with autocast():
                model_outputs = self.model(batch)
                loss_dict = self.criterion(model_outputs)
                total_loss = loss_dict["total_loss"]

            total_losses.update(total_loss.item(), len(batch["labels"]))
            cls_losses.update(loss_dict["classification_loss"].item(), len(batch["labels"]))
            align_losses.update(loss_dict["alignment_loss"].item(), len(batch["labels"]))
            cons_losses.update(loss_dict["consistency_loss"].item(), len(batch["labels"]))

            self.scaler.scale(total_loss).backward()
            self.scaler.step(self.optimizer)
            self.scaler.update()

            # ğŸ”§ ä¿®å¤: å¢å¼ºæ¢é’ˆç›‘æ§ï¼Œæ¯10ä¸ªbatchæ£€æŸ¥ä¸€æ¬¡
            if task0_param_to_watch is not None and (it % 10 == 0):
                task0_param_after_sum = task0_param_to_watch.sum().item()
                if abs(task0_param_after_sum - task0_param_before_sum) > 1e-6:
                    logger.critical(f"!!! [æ¢é’ˆ] è‡´å‘½é”™è¯¯ï¼šTask 0çš„å‚æ•°åœ¨è®­ç»ƒTask {self.task_id}æ—¶è¢«ä¿®æ”¹äº†ï¼")
                    logger.critical(f"è®­ç»ƒå‰: {task0_param_before_sum:.8f}, è®­ç»ƒå: {task0_param_after_sum:.8f}")
                    logger.critical(f"å·®å¼‚: {abs(task0_param_after_sum - task0_param_before_sum):.8f}")
                    
                    # ğŸ”§ é¢å¤–æ£€æŸ¥ï¼šéªŒè¯å½“å‰æ¿€æ´»çš„ä»»åŠ¡IDæ˜¯å¦æ­£ç¡®
                    try:
                        current_vision_task_id = self.model.backbone.vilt.encoder.layer[0].attention.attention.query.vision_adapter.current_task_id
                        logger.critical(f"å½“å‰è§†è§‰é€‚é…å™¨ä»»åŠ¡ID: {current_vision_task_id}, æœŸæœ›: {self.task_id}")
                    except Exception as e:
                        logger.error(f"æ— æ³•è·å–å½“å‰ä»»åŠ¡ID: {e}")

            if self.lr_scheduler and self.lr_scheduler_interval == "step":
                self.lr_scheduler.step()

            batch_time.update(time.perf_counter() - end)
            end = time.perf_counter()

            if (it + 1) % self.cfg.train.PRINT_FREQ == 0:
                progress.display(it + 1)
                self.tensorboard_logger.add_scalar(f"loss/task{self.task_id}_total", total_losses.avg, self.current_iter)
                self.tensorboard_logger.add_scalar(f"loss/task{self.task_id}_cls", cls_losses.avg, self.current_iter)
                self.tensorboard_logger.add_scalar(f"loss/task{self.task_id}_align", align_losses.avg, self.current_iter)
                self.tensorboard_logger.add_scalar(f"loss/task{self.task_id}_consist", cons_losses.avg, self.current_iter)

        if self.lr_scheduler and self.lr_scheduler_interval == "epoch":
            self.lr_scheduler.step()

    def prepare_incremental_task(self, task_id):
        """ğŸ”§ ä¼˜åŒ–12: ç®€åŒ–ä»»åŠ¡å‡†å¤‡æ—¥å¿—"""
        logger.info(f"=== å‡†å¤‡ä»»åŠ¡ {task_id} ===")
        
        if hasattr(self.model, "set_active_task"):
            self.model.set_active_task(task_id)
        
        self._verify_task_switching(task_id)
        
        self.task_id = task_id
        self.valid_class_range = (0, (task_id + 1) * self.num_labels_per_task)
        self.prepare_dataloaders()
        self.reset_optimizer_and_scheduler()
        
        logger.info(f"=== ä»»åŠ¡ {task_id} å‡†å¤‡å®Œæˆ ===")

    def _verify_task_switching(self, expected_task_id):
        """ğŸ”§ ä¿®å¤: éªŒè¯ä»»åŠ¡åˆ‡æ¢æ˜¯å¦æˆåŠŸ"""
        try:
            # æ£€æŸ¥ç¬¬ä¸€å±‚çš„queryé€‚é…å™¨
            first_layer_query = self.model.backbone.vilt.encoder.layer[0].attention.attention.query
            vision_adapter = first_layer_query.vision_adapter
            text_adapter = first_layer_query.text_adapter
            
            assert vision_adapter.current_task_id == expected_task_id, \
                f"è§†è§‰é€‚é…å™¨ä»»åŠ¡IDé”™è¯¯: æœŸæœ›{expected_task_id}, å®é™…{vision_adapter.current_task_id}"
            assert text_adapter.current_task_id == expected_task_id, \
                f"æ–‡æœ¬é€‚é…å™¨ä»»åŠ¡IDé”™è¯¯: æœŸæœ›{expected_task_id}, å®é™…{text_adapter.current_task_id}"
            
            # éªŒè¯å‚æ•°å†»ç»“çŠ¶æ€
            for task_idx in range(self.num_tasks):
                is_current_task = (task_idx == expected_task_id)
                
                # æ£€æŸ¥LoRAå‚æ•°çš„requires_gradçŠ¶æ€
                lora_A_grad = vision_adapter.lora_A_pools[task_idx].requires_grad
                lora_B_grad = vision_adapter.lora_B_pools[task_idx].requires_grad
                
                assert lora_A_grad == is_current_task, \
                    f"ä»»åŠ¡{task_idx}çš„LoRA_Aå‚æ•°çŠ¶æ€é”™è¯¯: æœŸæœ›{is_current_task}, å®é™…{lora_A_grad}"
                assert lora_B_grad == is_current_task, \
                    f"ä»»åŠ¡{task_idx}çš„LoRA_Bå‚æ•°çŠ¶æ€é”™è¯¯: æœŸæœ›{is_current_task}, å®é™…{lora_B_grad}"
            
            logger.info(f"âœ… ä»»åŠ¡åˆ‡æ¢éªŒè¯é€šè¿‡: å½“å‰æ´»è·ƒä»»åŠ¡ {expected_task_id}")
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡åˆ‡æ¢éªŒè¯å¤±è´¥: {e}")
            raise e

    def _verify_task_switching(self, expected_task_id):
        """ğŸ”§ ä¼˜åŒ–9: ç®€åŒ–éªŒè¯è¿‡ç¨‹ï¼Œåªæ£€æŸ¥å…³é”®ç»„ä»¶"""
        try:
            # åªæ£€æŸ¥ç¬¬0å±‚çš„queryé€‚é…å™¨ä½œä¸ºä»£è¡¨
            first_layer_query = self.model.backbone.vilt.encoder.layer[0].attention.attention.query
            vision_adapter = first_layer_query.vision_adapter
            text_adapter = first_layer_query.text_adapter
            
            # éªŒè¯ä»»åŠ¡ID
            assert vision_adapter.current_task_id == expected_task_id, \
                f"ä»»åŠ¡IDé”™è¯¯: æœŸæœ›{expected_task_id}, å®é™…{vision_adapter.current_task_id}"
            
            # éªŒè¯å…³é”®å‚æ•°çŠ¶æ€ - åªæ£€æŸ¥å½“å‰ä»»åŠ¡å’Œå‰ä¸€ä¸ªä»»åŠ¡
            tasks_to_check = [expected_task_id]
            if expected_task_id > 0:
                tasks_to_check.append(expected_task_id - 1)
            
            for task_idx in tasks_to_check:
                is_current_task = (task_idx == expected_task_id)
                lora_A_grad = vision_adapter.lora_A_pools[task_idx].requires_grad
                
                assert lora_A_grad == is_current_task, \
                    f"ä»»åŠ¡{task_idx}å‚æ•°çŠ¶æ€é”™è¯¯: æœŸæœ›{is_current_task}, å®é™…{lora_A_grad}"
            
            logger.info(f"âœ… ä»»åŠ¡åˆ‡æ¢éªŒè¯é€šè¿‡: å½“å‰æ´»è·ƒä»»åŠ¡ {expected_task_id}")
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡åˆ‡æ¢éªŒè¯å¤±è´¥: {e}")
            raise e

    def reset_optimizer_and_scheduler(self):
        """ğŸ”§ ä¿®å¤2: ä¿®å¤å˜é‡åé”™è¯¯"""
        # è·å–æ‰€æœ‰å¯è®­ç»ƒå‚æ•°
        trainable_params = []
        layer_counts = {}
        
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                trainable_params.append(param)
                
                # ç»Ÿè®¡æ¯å±‚å‚æ•°æ•°é‡
                if "layer." in name:
                    layer_num = name.split("layer.")[1].split(".")[0]
                    layer_counts[layer_num] = layer_counts.get(layer_num, 0) + param.numel()
        
        if not trainable_params:
            logger.error(f"âŒ ä»»åŠ¡ {self.task_id} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯è®­ç»ƒå‚æ•°!")
            raise ValueError(f"No trainable parameters found for task {self.task_id}")
        
        total_params = sum(p.numel() for p in trainable_params)
        active_layers = len(layer_counts)
        
        logger.info(f"âœ… ä»»åŠ¡ {self.task_id}: {len(trainable_params)} ä¸ªå¯è®­ç»ƒå‚æ•° "
                   f"(æ€»è®¡ {total_params}, æ¶‰åŠ {active_layers} å±‚)")
        
        # ğŸ”§ ä¿®å¤3: æ­£ç¡®è®¿é—®å­—å…¸çš„é”®å€¼å¯¹
        sample_layers = sorted(layer_counts.keys())[:3]
        if sample_layers:
            sample_info = ", ".join([f"Layer{k}:{layer_counts[k]}" for k in sample_layers])
            logger.info(f"å‚æ•°åˆ†å¸ƒæ ·ä¾‹: {sample_info}")
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        self.optimizer = build_optimizer(self.cfg.train.optimizer, trainable_params)
        
        num_training_steps = len(self.train_dataloader) * self.cfg.train.EPOCHS
        self.lr_scheduler = None if "lr_scheduler" not in self.cfg.train else build_lr_scheduler(
            self.cfg.train.lr_scheduler, self.optimizer, num_training_steps=num_training_steps
        )
        self.lr_scheduler_interval = None if "lr_scheduler" not in self.cfg.train else self.cfg.train.lr_scheduler.LR_SCHEDULER_INTERVAL



    def prepare_dataloaders(self):
        self.train_dataloader = self.dataloaders["train"][self.task_id]
        self.val_dataloaders = self.dataloaders["val"][self.task_id]

    @torch.no_grad()
    def _validate_one_dataloader(self, val_dataloader, task_id=0):
        """ğŸ”§ æ ¸å¿ƒä¿®å¤ï¼šéªŒè¯æ—¶ä¸´æ—¶åˆ‡æ¢åˆ°ç›®æ ‡ä»»åŠ¡"""
        logits, labels = [], []
        self.model.eval()

        # ğŸ”§ å…³é”®ä¿®å¤1ï¼šè®°å½•å½“å‰æ¿€æ´»çš„ä»»åŠ¡
        current_active_task = self.model.backbone.vilt.encoder.layer[0].attention.attention.query.vision_adapter.current_task_id
        
        # ğŸ”§ å…³é”®ä¿®å¤2ï¼šå¦‚æœè¦éªŒè¯çš„ä»»åŠ¡ä¸æ˜¯å½“å‰æ¿€æ´»çš„ä»»åŠ¡ï¼Œä¸´æ—¶åˆ‡æ¢
        need_task_switch = (task_id != current_active_task)
        if need_task_switch:
            logger.info(f"ğŸ”„ éªŒè¯æ—¶ä¸´æ—¶åˆ‡æ¢: ä»»åŠ¡{current_active_task} -> ä»»åŠ¡{task_id}")
            self.model.backbone.set_active_task(task_id)

        try:
            # éªŒè¯æ—¶çš„æ¢é’ˆæ£€æŸ¥
            if task_id == 0:
                try:
                    param_to_check_in_val = self.model.backbone.vilt.encoder.layer[0].attention.attention.query.vision_adapter.lora_A_pools[0]
                    sum_in_val = param_to_check_in_val.sum().item()
                    logger.info(f"[æ¢é’ˆ #4] éªŒè¯Task {task_id}æ—¶, Task 0å‚æ•°æŒ‡çº¹: {sum_in_val:.6f}")
                except Exception as e:
                     logger.error(f"[æ¢é’ˆ #4] æ— æ³•è·å–å‚æ•°: {e}")

            for _, batch in tqdm(enumerate(val_dataloader), desc=f"task{task_id}", total=len(val_dataloader)):
                inputs_on_device = {k: v.to(self.device) for k, v in batch['inputs'].items()}
                batch['inputs'] = inputs_on_device
                batch['labels'] = batch['labels'].to(self.device)
                batch['missing_types'] = batch['missing_types'].to(self.device)

                with autocast():
                    # ğŸ”§ å…³é”®ä¿®å¤3ï¼šå¼ºåˆ¶ä½¿ç”¨æŒ‡å®šä»»åŠ¡çš„ä¸“å®¶ç³»ç»Ÿ
                    outputs = self.model(batch, force_task_id=task_id)

                logits.append(outputs["logits"].cpu())
                labels.append(batch["labels"].cpu())

        finally:
            # ğŸ”§ å…³é”®ä¿®å¤4ï¼šéªŒè¯å®Œæˆåæ¢å¤åŸå§‹ä»»åŠ¡çŠ¶æ€
            if need_task_switch:
                logger.info(f"ğŸ”„ éªŒè¯åæ¢å¤: ä»»åŠ¡{task_id} -> ä»»åŠ¡{current_active_task}")
                self.model.backbone.set_active_task(current_active_task)

        logits = torch.vstack(logits)[:, :self.valid_class_range[1]]
        if self.cfg.data.MULTI_LABEL:
            labels = torch.vstack(labels)[:, :self.valid_class_range[1]]
        else:
            labels = torch.hstack(labels)

        return self.evaluator({
            "logits": logits,
            "labels": labels,
        }, num_classes=labels.shape[1] if self.cfg.data.MULTI_LABEL else None)

    @torch.no_grad()
    def _validate_tasks(self, dataloaders, num_tasks):
        return [self._validate_one_dataloader(dataloaders[task_id], task_id) for task_id in range(num_tasks)]

    @torch.no_grad()
    def validate(self):
        self.model.eval()
        return self._validate_tasks(self.val_dataloaders, self.task_id + 1)

    @torch.no_grad()
    def test(self, dataloaders, task_id):
        self.prepare_incremental_task(task_id)
        self.model.eval()
        return self._validate_tasks(dataloaders, task_id + 1)

    def save_checkpoint(self, metrics, task_id=None, is_best=False):
        ckpt = {
            "model": self.model.state_dict(),
            "optimizer": self.optimizer.state_dict(),
            "criterion": self.criterion.state_dict(),
            "current_epoch": self.current_epoch,
            "metrics": metrics,
            "task_id": task_id,
        }
        if self.lr_scheduler:
            ckpt.update({"lr_scheduler": self.lr_scheduler.state_dict()})
        self.checkpoint.save(**ckpt, is_best=is_best)

    def load_checkpoint(self, checkpoint_path, task_id=None):
        """ğŸ”§ ä¿®å¤3: å¢å¼ºçš„checkpointåŠ è½½é€»è¾‘"""
        logger.info(f"æ­£åœ¨åŠ è½½checkpoint: {checkpoint_path}")
        
        try:
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
        except Exception as e:
            logger.error(f"æ— æ³•è¯»å–checkpointæ–‡ä»¶: {e}")
            raise e
        
        # ç¡®å®šä»»åŠ¡ID
        if task_id is None:
            if "task_id" in checkpoint:
                task_id = checkpoint["task_id"]
            else:
                logger.warning("checkpointä¸­æ²¡æœ‰task_idä¿¡æ¯ï¼Œå‡è®¾ä¸ºtask 0")
                task_id = 0
        
        logger.info(f"å‡†å¤‡åŠ è½½ä»»åŠ¡ {task_id} çš„checkpoint")
        
        # ğŸ”§ ä¿®å¤4: åœ¨åŠ è½½æ¨¡å‹å‚æ•°å‰ï¼Œç¡®ä¿æ¨¡å‹ç»“æ„æ­£ç¡®
        if hasattr(self.model, "set_active_task"):
            self.model.set_active_task(task_id)
            logger.info(f"å·²å°†æ¨¡å‹åˆ‡æ¢åˆ°ä»»åŠ¡ {task_id}")
        
        # åŠ è½½æ¨¡å‹å‚æ•°
        try:
            if "model" in checkpoint:
                missing_keys, unexpected_keys = self.model.load_state_dict(checkpoint["model"], strict=False)
                if missing_keys:
                    logger.warning(f"åŠ è½½æ—¶ç¼ºå¤± {len(missing_keys)} ä¸ªé”®")
                if unexpected_keys:
                    logger.warning(f"åŠ è½½æ—¶å¿½ç•¥ {len(unexpected_keys)} ä¸ªå¤šä½™é”®")
                logger.info("âœ… æ¨¡å‹å‚æ•°åŠ è½½æˆåŠŸ")
            else:
                logger.error("checkpointä¸­æ²¡æœ‰æ¨¡å‹å‚æ•°")
                raise KeyError("No 'model' key found in checkpoint")
        except Exception as e:
            logger.error(f"æ¨¡å‹å‚æ•°åŠ è½½å¤±è´¥: {e}")
            raise e
        
        logger.info(f"âœ… æˆåŠŸåŠ è½½checkpoint (ä»»åŠ¡ID: {task_id})")

    def display_metrics(self, metrics):
        s = "Metrics:\n" + "=" * 50 + "\n"
        for task_id, metric in enumerate(metrics):
            for k, v in metric.items():
                s += f"Task {task_id} {k}: {v:.2f}\n"
        s += "=" * 50
        logger.info(s)


def move_to_device(batch, device):
    if isinstance(batch, torch.Tensor):
        return batch.to(device)
    if isinstance(batch, dict):
        return {k: move_to_device(v, device) for k, v in batch.items()}
    if isinstance(batch, list):
        return [move_to_device(v, device) for v in batch]
    return batch